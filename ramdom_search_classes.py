# -*- coding: utf-8 -*-
"""Ramdom_Search_Classes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJw4Q1F3TYv8okhNqNTtw5CdCFH7-vrh
"""

import numpy as np
import tensorflow as tf 
import keras
from keras import models
from keras import layers
from keras import optimizers
from keras.applications.resnet50 import ResNet50
from keras.layers import Flatten, Dense, Dropout, UpSampling2D
from keras.applications.resnet50 import preprocess_input
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Activation, Convolution2D, BatchNormalization, GlobalAveragePooling2D, Dropout
from keras.models import Sequential
from keras.initializers import RandomNormal
from keras.datasets import cifar10
import matplotlib.pyplot as plt
from keras.utils.np_utils import to_categorical
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
from keras.wrappers.scikit_learn import KerasClassifier
import keras.backend as K
from keras.wrappers.scikit_learn import KerasClassifier
from keras.callbacks import Callback,ModelCheckpoint
from keras.datasets import cifar10
import numpy as np
import matplotlib.pyplot as plt
import random as rand
from keras.callbacks import ModelCheckpoint
from keras.optimizers import Adam
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
import sklearn
from sklearn.model_selection import ShuffleSplit

def get_data(skew_ratio, num_of_class):
  
  (x_train, y_train), (x_test, y_test) = cifar10.load_data()
  y_train.reshape((50000))
  y_test.reshape((10000))
  # integers = rand.randint(1,3)
  integers = num_of_class
  skew_amount = int(5000/skew_ratio)
  class_index = []
  class_index = np.random.choice(10, integers, replace = False)

  for j in class_index:
    indices = np.where(y_train == j)[0]
    np.random.shuffle(indices)
    delete_indices = indices[skew_amount:]
    y_train = np.delete(y_train, list(delete_indices))
    x_train = np.delete(x_train, list(delete_indices), axis = 0)
    
  return x_train, y_train, x_test, y_test, class_index

# ONLY WHEN REQUIRED
path = "/content/drive/My Drive/CIFAR10/Imbalance/Class_Fraction_Constant/3/50"
x_train, y_train, x_test, y_test, class_index  = get_data(5, 3)

# np.savez(path + "/data.npz",name1 = x_train, name2 = y_train, name3 = x_test, name4 = y_test)
num_classes = 10

y_test_1 =  y_test
y_train_1 = y_train

num_classes = 10
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

def get_f1(y_true, y_pred): #taken from old keras source code
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    recall = true_positives / (possible_positives + K.epsilon())
    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())
    return f1_val

def nn_model():
  classifier = Sequential()
  random_uniform = RandomNormal(mean=0.0, stddev=0.01, seed=None)

  # classifier.add(Dropout(0.25,input_shape = (32,32,3)))

  classifier.add(Convolution2D(96,(3,3), input_shape = (32,32,3), padding = 'same', strides = 1,kernel_initializer =random_uniform, bias_initializer = "zeros" ))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Dropout(0.25))

  classifier.add(Convolution2D(96,(3,3), padding = 'same', strides = 1,kernel_initializer =random_uniform))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Dropout(0.25))

  classifier.add(Convolution2D(96,(3,3), padding = 'same', strides = 2,kernel_initializer =random_uniform, bias_initializer = "zeros"))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Dropout(0.25))

  classifier.add(Convolution2D(192,(3,3), padding = 'same', strides = 1,kernel_initializer =random_uniform, bias_initializer = "zeros"))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Dropout(0.50))

  classifier.add(Convolution2D(192,(3,3), padding = 'same', strides = 1,kernel_initializer =random_uniform, bias_initializer = "zeros"))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Dropout(0.50))

  classifier.add(Convolution2D(192,(3,3), padding = 'same', strides = 2,kernel_initializer =random_uniform, bias_initializer = "zeros"))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Dropout(0.50))

  classifier.add(Convolution2D(192,(3,3), padding = 'same', strides = 1,kernel_initializer =random_uniform, bias_initializer = "zeros"))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Dropout(0.50))

  classifier.add(Convolution2D(192,(1,1), padding = 'same', strides = 1,kernel_initializer =random_uniform, bias_initializer = "zeros"))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(Convolution2D(10,(1,1), padding = 'same', strides = 1,kernel_initializer =random_uniform, bias_initializer = "zeros"))
  classifier.add(BatchNormalization())
  classifier.add(Activation('relu'))

  classifier.add(GlobalAveragePooling2D())
  classifier.add(Activation("softmax"))
  callbacks_list = []
  checkpoint = ModelCheckpoint("/content/drive/My Drive/CIFAR10/Imbalance/Class_Fraction_Constant/3/50/Focal Loss/model-{epoch:03d}-{get_f1:03f}-{val_get_f1:03f}.h5", verbose=1, monitor='val_get_f1',save_best_only=True, mode='max')
  callbacks_list = [checkpoint]

  adam = optimizers.Adam(learning_rate=0.001,decay = 1e-4, beta_1=0.9, beta_2=0.999, amsgrad=False)
  classifier.compile(optimizer = adam , loss= "categorical_crossentropy", metrics = [get_f1])
  return classifier

import numpy as np
from scipy import interp
import matplotlib.pyplot as plt
from itertools import cycle
from sklearn.metrics import roc_curve, auc

def f1(Y_test, y_pred):d
  y_test = np.argmax(Y_test, axis=1)
  cm = confusion_matrix(y_test, y_pred)
  accuracy = np.trace(cm) / float(np.sum(cm))
  print("\nValidation_Accuracy = ", accuracy, "\n")
  return accuracy

estimator = KerasClassifier(build_fn = nn_model, epochs = 40, batch_size = 128, verbose = 1)

# Tunable Parameters
weights = np.linspace(0.05,0.5,num = 20)
index = np.where(np.bincount(y_train_1)==np.bincount(y_train_1).min())
class_weights = [[x]*10 for x in weights]
for i in range(20):
  for j in np.nditer(index):
    class_weights[i][j] = 1 - weights[i]


param_grid_1 = dict(class_weight = class_weights)

# Fitting the model
scorer_1 = sklearn.metrics.make_scorer(f1,  greater_is_better=True)
scorer = sklearn.metrics.make_scorer(recall_score)
cv = ShuffleSplit(n_splits=1, test_size=0.1, random_state=0)
random_grid = RandomizedSearchCV(estimator = estimator, param_distributions = param_grid_1, verbose = 2, scoring = scorer_1, return_train_score = True, cv =cv)
grid_result = random_grid.fit(x_train, y_train)

random_grid.cv_result_

dir(random_grid)

random_grid.best_params_

random_grid.best_score_

random_grid.best_params_

random_grid.error_score

random_grid.return_train_score

random_grid.get_params